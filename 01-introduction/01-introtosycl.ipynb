{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d03299-b623-4a16-bd3b-0466edaa2b7e",
   "metadata": {},
   "source": [
    "# 01 - Introduction to SYCL Programming for GPUs\n",
    "\n",
    "Argonne Leadership Computing Facility, UChicago Argonne, LLC, All rights reserved\n",
    "\n",
    "In today's fast-paced world of HPC, **heterogenous systems** — which combine CPUs, GPUs, and other \n",
    "accelerators — are crucial for scaling computational workloads. However, programming for such diverse\n",
    "architectures can be a challenge. This is where **SYCL** comes in.\n",
    "\n",
    "**SYCL (pronounced \"sickle\")** is an open standard for single-source programming designed to simplify\n",
    "development for heterogeneous systems. SYCL allows you to write **modern C++** code that runs on CPUs,\n",
    "GPUs, and other accelerators without having to write separate code for each architecture. Whether you're\n",
    "a seasoned developer of just starting, SYCL helps you focus on writing algorithms, while it handles the\n",
    "underlying complexities of device management and memory allocation.\n",
    "<!--\n",
    "In the rapidly evolving world of computing, the ability to harness the\n",
    "power of heterogeneous systems—where CPUs coexist with GPUs and other\n",
    "accelerators—has become increasingly vital. **SYCL** stands as a\n",
    "cutting-edge, single-source programming model designed to bridge this\n",
    "gap. Developed to be used with modern C++, SYCL abstracts the\n",
    "complexities associated with direct accelerator programming, making it\n",
    "accessible to both novice and experienced developers.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf14782-a383-4c36-837f-4b7e75a64470",
   "metadata": {},
   "source": [
    "### What is SYCL?\n",
    "\n",
    "SYCL is an open standard developed by the **Khronos Group**, the same group\n",
    "responsible for **OpenCL**. It allows developers to write code for\n",
    "heterogeneous systems using completely standard C++. This means that the\n",
    "same code can target CPUs, GPUs, DSPs, FPGAs, and other types of\n",
    "accelerators without modification. \n",
    "\n",
    "SYCL builds upon the foundation laid\n",
    "by OpenCL, offering a higher level of abstraction and deeper integration\n",
    "with C++. While OpenCL requires developers to manage host and device code separtely, SYCL allows both to be written in a single, unified C++ source file. This enables a more intuitive and efficient programming experience, making it easier to develop portabl and high-performance applications for diverse hardware platforms.\n",
    "\n",
    "<img width=\"800\" src=https://www.khronos.org/assets/uploads/apis/2022-sycl-diagram.jpg>\n",
    "Image Source. https://www.khronos.org/sycl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76aa5e3-6ebb-4942-ba0c-0ca0b8251efc",
   "metadata": {},
   "source": [
    "<img src=https://raw.githubusercontent.com/oneapi-src/oneAPI-samples/495ff2bb29b50698e9c6d3b12f7d8cf476e73d02/DirectProgramming/C++SYCL/Jupyter/oneapi-essentials-training/01_oneAPI_Intro/Assets/oneapi1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7fa39-433f-4693-9058-28c6b66553bd",
   "metadata": {},
   "source": [
    "### Advantages of SYCL\n",
    "\n",
    "One of the primary advantages of SYCL is its ability to integrate\n",
    "seamlessly with C++17 and upcoming versions, enabling features like\n",
    "lambda functions, auto-typing, and templating. This integration not only\n",
    "improves the programmability and readability of the code but also\n",
    "leverages the **type safety** and **performance optimizations** provided by\n",
    "modern C++. Here are a few key benefits: - \n",
    "* **Single-Source Development**: Unlike traditional approaches that might require maintaining separate code bases for different architectures (e.g., separate code for CPUs and GPUs), SYCL unifies the code into a **single source**. This simplifies development and reduces maintenance burdens, making it easier to write code that works across different devices without duplication.\n",
    "* **Cross-Platform Portability**: SYCL code can be executed on any device that has a compatible SYCL runtime, providing true cross-platform capabilities. Whether you're working with **Intel GPUs, AMD GPUs, NVIDIA GPUs,** or even FPGAs, the same SYCL codebase can be compiled and executed, ensuring broad compatibility.\n",
    "* **Performance**: With SYCL, developers do not have to sacrifice performance for portability. It allows fine control over **parallel execution** and **memory management**, which are critical for achieving optimal performance on GPUs and other accelerators. SYCL's abstraction ensures you can write high-level code without losing the ability to perform low-level optimizations when needed.\n",
    "\n",
    "As GPUs continue to play a crucial role in fields ranging from\n",
    "**scientific computing** to **machine learning**, mastering SYCL can provide\n",
    "developers with the tools needed to fully exploit the capabilities of\n",
    "these powerful devices. The following sections will guide you through\n",
    "setting up your development environment, understanding the core concepts\n",
    "of SYCL, and walking you through practical examples to kickstart your\n",
    "journey in high-performance computing with SYCL.\n",
    "\n",
    "<!--\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "This introduction sets the stage for learning SYCL by highlighting its\n",
    "relevance, advantages, and integration with modern C++. It aims to build\n",
    "a strong foundation for the subsequent sections that delve deeper into\n",
    "SYCL programming.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec947dc-119b-4f4f-935a-01db51b5d7ab",
   "metadata": {},
   "source": [
    "# Basics of a SYCL Kernel \n",
    "<!--\n",
    "In SYCL, all computations are submitted through a queue. This queue is associated with a device, and any computation assigned to the queue is executed on this device[^1].\n",
    "This is how we check if a gpu is available for use and then initialize a sycl queue for a gpu:\n",
    "-->\n",
    "In SYCL, computations are submitted to a **queue**, which is associated with a specific device (such as a CPU, GPU, or accelerator). The **queue** is the core abstraction that handles task submission and ensures that your kernels (functions that run on the device) are executed on the chosen hardware.\n",
    "\n",
    "### Device Selection\n",
    "One of SYCL's strengths is the ability to choose the device on which your code will execute. This selection is made through **device selectors**, which help determine whether the code runs on a CPU, GPU, or another accelerator.\n",
    "\n",
    "Here's how you can check if a GPU is available and initialize a SYCL queue to run on that GPU:\n",
    "```c++\n",
    "// Check for available GPU devices\n",
    "auto selector = sycl::gpu_selector{};           // Select a GPU device\n",
    "auto myQueue = sycl::queue{selector};           // Create a queue for GPU\n",
    "```\n",
    "SYCL also provides other device selectors for different platforms:\n",
    "* `sycl::default_selector_v`: Automatically selects the best available device (GPU if available, otherwise CPU or another device).\n",
    "* `sycl::gpu_selector{}`: Specifically selects a GPU if present.\n",
    "* `sycl::cpu_selector{}`: Selects a CPU for execution.\n",
    "* `sycl::accelerator_selector{}`: Selects a specialized accelerator device like an FPGA.\n",
    "  \n",
    "Each selector is designed to give developers control over the type of hardware used for computations. If you dont' have a GPU or need to run the code on a CPU for testing purposes, the `cpu_selector{}` provides an easy fallback.\n",
    "\n",
    "### Creating a Queue\n",
    "After selecting a device, the next step is to create a **queue**. The queue manages the execution tasks (such as kernel functions) on the chosen device. Once a queue is created, you can submit tasks to it.\n",
    "```c++\n",
    "// Create a queue using the GPU selctor\n",
    "auto myQueue = sycl::queue{sycl::gpu_selector{}};\n",
    "```\n",
    "Here, the queue is associated with a GPU. If no GPU is available, SYCL will throw an exception, which you can handle to provide a fallback, such as using the CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6d106-24ec-4aed-a169-3c0c8d74a8ab",
   "metadata": {},
   "source": [
    "\n",
    "# Understanding SYCL Kernel Command Group Execution\n",
    "\n",
    "A **command group** is a fundamental construct that encapsulates a set of operations meant to be executed on a device. These operations can include tasks like kernel execution, memory management, or synchronization. The **command group** is submitted to a **queue**, and within this group, dependencies between tasks and data are managed to ensure that execution occurs in the correct order on the device.\n",
    "\n",
    "### Submitting a Command Group\n",
    "\n",
    "When you sumit work to a SYCL device, you do so through a **command group**. This is done using the `submit` function of the queue, which accepts a lambda function to define the operations you want to execute.\n",
    "\n",
    " ```c++\n",
    "// Submit a command group to the queue\n",
    "myQueue.submit([&](sycl::handler &cgh) {\n",
    "  // Command Group Function:\n",
    "  // Inside this lambda, we define the operations to be performed on the device\n",
    "  // For example, kernel execution, data transfers, etc.\n",
    "  // Lambda functions are explored further below\n",
    "})\n",
    "```\n",
    "At the heart of the command group is the **command group handler (cgh)**, which acts as an intermediary between the host (CPU) and the device (GPU or other accelerators). The handler is used to:\n",
    "\n",
    "* Define **kernel execution**: Specify the operations to be carried out on the device.\n",
    "* Establish **data dependencies**: Ensure that the necessary data is available on the device when the kernel executes.\n",
    "* Manage **memory accessors**: Allow access to buffers and other memory resources across host and device.\n",
    "\n",
    "<img width=\"255\" alt=\"\" src=\"images/image11.png\" >\n",
    "\n",
    "> The diagram illustrates the process of defining and submitting a SYCL command group.\n",
    "> It begins with a call to the `submit` function on a SYCL queue, which initiates the creation of a command group.\n",
    "> The `submit` function takes a command group function as its argument, within which a command group handler `cgh` is created.\n",
    "> * Inside the command group function, the handler is used to:\n",
    ">   * Specify dependencies between tasks.\n",
    ">   * Define the kernel funciton (the computation to be executed on the device).\n",
    ">   * Set up accessors for memory objects that the kernel will use.\n",
    ">\n",
    ">Once these elements are defined, the command group is assembled and submitted for execution on the device.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417cc05-18bb-48c6-af6a-18e18fb69c08",
   "metadata": {},
   "source": [
    "# Enqueuing A Kernel\n",
    "\n",
    "In SYCL, all computations are submitted through a queue. A queue is\n",
    "associated with a device, and any computation assigned to the queue is\n",
    "executed on this device. As a developer, you control the flow of computations by submitting **kernels** (parallel tasks) to the queue.\n",
    "\n",
    "### Managing Data in SYCL\n",
    "\n",
    "To efficiently execute kernels, SYCL provides two primary methods for managing data between the host (CPU) and device (GPU or other accelerators): \n",
    "\n",
    "1. **Buffer/Accessor Model:**\n",
    "This Buffer/Accessor model is the traditional approach in SYCL and provides robust memory management and synchronization mechanisms. Buffers are used to store data, and accessors define how kernels access and manipulate this data.\n",
    "\n",
    "The SYCL runtime automatically handles the transfer of data between the host and device, ensuring that data remain **consistent** and **synchronized** across different memory spaces.\n",
    "\n",
    "Some key benefits include:\n",
    "\n",
    "* **Automatic Memory Management**: SYCL takes care of copying data between host and device, ensuring the correct data is available at the right time.\n",
    "*  **Data Consistency**: The runtime manages the synchronization of data across devices, which simplifies programmingin heterogenous environemnts\n",
    "\n",
    "``` c++\n",
    "sycl::buffer<float, 1> buf(data, sycl::range<1>(data_size));\n",
    "myQueue.submit([&](sycl::handler &cgh) {\n",
    "  // Access the buffer in read-write mode\n",
    "  auto acc = buf.get_access<sycl::access::mode::read_write>(cgh);\n",
    "  cgh.parallel_for(sycl::range<1>(data_size), [=](sycl::id<1> idx) {\n",
    "    // Modify buffer data\n",
    "    acc[idx] *= 2;\n",
    "  });\n",
    "});\n",
    "```\n",
    "* A **buffer** is created to hold the data.\n",
    "* The kernel accesses the buffer using an **accessor**, ensuring safe access and synchronization.\n",
    "* SYCL ensures that the correct data is copied to the device before the kernel runs and that modified data is transferred back to the host afterward.\n",
    "\n",
    "2. **Unified Shared Memory (USM) Model:**\n",
    "The USM model offers a more flexible way to manage memory, especially for developers who need fine control over memory allocation. With USM, you can allocate memory that is shared between the host and device, eliminating the need for explicit buffers and accessors. This simplifies certain types of programs, such as those where direct pointer manipulation is needed.\n",
    "\n",
    "USM gives developers:\n",
    "\n",
    "* **Simplified Memory Access**: USM allows the host and device to directly access the same memory locations, which can simplify memory management in some cases.\n",
    "* **Fine-Grained Control**: Developers have more control over when and how memory is allocated, transferred, and synchronized between the host and device.\n",
    "\n",
    "``` c++\n",
    "float* usm_data = sycl::malloc_shared<float>(data_size, myQueue);\n",
    "std::copy(data.begin(), data.end(), usm_data); // Copy data to shared memory\n",
    "\n",
    "myQueue.submit([&](sycl::handler& cgh) {\n",
    "  cgh.parallel_for(sycl::range<1>(data_size), [=](sycl::id<1> idx) {\n",
    "    usm_data[idx] *= 2; // modify data Directly in shared memory\n",
    "  });\n",
    "});\n",
    "\n",
    "myQueue.wait() // ensure the task is compelted\n",
    "```\n",
    "* Memory is allocated using `malloc_shared`, which allows both the host and device to directly access the same data.\n",
    "* The kernel modifies the data in place, without the need for buffers or accessors.\n",
    "* The use of `wait()` ensures that the kernel completes before the data is accessed on the host again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93641762-fee2-4e80-acc7-949e1956544f",
   "metadata": {},
   "source": [
    "# Scheduling\n",
    "\n",
    "A schedulre is a component responsible for managing the order and\n",
    "execution of tasks on computational resources.\n",
    "\n",
    "#### Scheduling Overview\n",
    "<img width=\"600\" src=\"images/image33.png\">\n",
    "\n",
    "-   When the **submit** function is called, it creates a command group\n",
    "    handler (**`cgh`**) and submits it to the scheduler.\n",
    "-   The scheduler is responsible for executing the commands on the\n",
    "    designated target device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc94a5c-f22c-4146-b4d2-ed45585ce325",
   "metadata": {},
   "source": [
    "# Command Groups\n",
    "\n",
    "A command group is a fundamental construct that encapsulates a set of\n",
    "operations meant to be executed on a device.\n",
    "\n",
    "<img width=\"305\" src=\"images/image11.png\" >\n",
    "\n",
    "\n",
    "\n",
    "-   Command groups are defined by calling the **submit** function on the\n",
    "    queue.\n",
    "-   The **submit** function takes a command group handler (`cgh`) which\n",
    "    facilitates the composition of the command group.\n",
    "-   Inside the **submit** function, a handler is created and passed to\n",
    "    the `cgh`.\n",
    "-   This handler is then used by the `cgh` to assemble the command\n",
    "    group.\n",
    "\n",
    "``` c++\n",
    "myQueue.submit([&](sycl::handler &cgh) {\n",
    "  /* Command group function */\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf5535-9ccd-4304-b650-b15b9b44abb4",
   "metadata": {},
   "source": [
    "### Lambda functions \n",
    "\n",
    "In SYCL, lambdas play a crucial role similar to their use in general programming, but they are specifically tailored for defining operations on data that will be executed on parallel devices like GPUs and CPUs. Like in other programming contexts, lambdas in SYCL allow for writing concise, anonymous functions. This capability is especially valuable in SYCL due to the nature of parallel computing, where operations often need to be defined locally and executed across a range of data elements.\n",
    "\n",
    "Lambdas in SYCL are structured similarly to standard C++ lambdas, but are specifically utilized within the SYCL framework to define the functionality of kernels that execute on parallel compute devices. The basic syntax of a lambda in SYCL can be summarized as follows:\n",
    "\n",
    "```cpp\n",
    "[capture_clause](input_signature) -> return_specification {\n",
    "    // execution_block\n",
    "}\n",
    "```\n",
    "\n",
    "In the context of SYCL you typically encounter the following types of captures:\n",
    "\n",
    "- `[]` : Captures nothing from the enclosing scope. This is used when the lambda does not need to access any external variables.\n",
    "\n",
    "- `[&]` : Captures all accessible variables from the surrounding scope by reference. Useful when you need to modify the external variables or when copying them is expensive.\n",
    "\n",
    "- `[=]` : Captures all accessible variables from the surrounding scope by value. This is safe when the lambda is executed asynchronously or on a separate device, ensuring that it works with a consistent copy of the data.\n",
    "\n",
    "For example, when defining a SYCL kernel, a developer might use a lambda to specify the computation that each thread should perform on the elements of a buffer. This lambda can capture necessary variables from its surrounding scope to use within the kernel execution:\n",
    "\n",
    "```c++\n",
    "buffer<float, 1> buf(data, range<1>(data_size));\n",
    "myQueue.submit([&](handler& cgh) {\n",
    "    auto acc = buf.get_access<access::mode::read_write>(cgh);\n",
    "    cgh.parallel_for(range<1>(data_size), [=](id<1> idx) {\n",
    "        acc[idx] *= 2; // Example operation: double each element\n",
    "    });\n",
    "});\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea597a-8bfb-4614-84e3-530974ed1614",
   "metadata": {},
   "source": [
    "## Enqueuing SYCL Kernel Function Single_task example\n",
    "\n",
    "Let's walk through a simple example of enqueuing a single_task kernel in SYCL. The `single_task` kernel is one of the most straightforward ways to run a task on a device, perfect for situations where you only need to execute one operation without any parallelization. Think of it as a \"hello world\" for SYCL kernels.\n",
    "\n",
    "We start by setting up the basics.\n",
    "```c++\n",
    "// Select GPU devices\n",
    "auto gpu_selector = sycl::gpu_selector{};\n",
    "auto myQueue = sycl::queue{gpu_selector};\n",
    "```\n",
    "Here, we’re creating a queue for a GPU device using the `sycl::gpu_selector`. If SYCL finds an available GPU on your system, this selector will make sure your code runs on it. If no GPU is available, you’d get an exception, which you could handle to gracefully fall back to a CPU or another device.\n",
    "\n",
    "Now, moving on to submitting a task.\n",
    "``` c++\n",
    "myQueue.submit([&](sycl::handler &cgh) {\n",
    "    // Create a stream for output within kernel\n",
    "    auto os = sycl::stream{128, 128, cgh};\n",
    "    // Execute a single task\n",
    "    cgh.single_task([=]() {\n",
    "      os << \"Hello World!\" << sycl::endl;\n",
    "    });\n",
    "    \n",
    "}).wait(); // Wait for completion of gpuQueue\n",
    "```\n",
    "This is where the magic happens. We use the `submit` function to send a **command group** to the queue. The command group is where we define what the device (GPU, in this case) should actually do. Inside the command group, we use the **command group handler (cgh)** to tell the device what task we want to run.\n",
    "\n",
    "You might notice we're using **sycl::stream** here. This is a handy tool in SYCL that lets you print from within the kernel. It’s not something you’ll use in every program, but it’s incredibly useful for debugging or when you want to output something directly from the device. In our case, it’s printing **\"Hello World!\"** from the GPU.\n",
    "\n",
    "### Why Use `single_task`?\n",
    "\n",
    "The **single_task** kernel, as its name suggests, runs exactly once. Unlike more complex kernels, which may run in parallel across multiple data points (more on that later), this kernel executes a single instance of the task. It’s a great starting point for writing simple kernels or testing device functionality.\n",
    "\n",
    "In this case, we’ve used it to print `\"Hello World!\"`, but you could imagine using `single_task` to run any simple, non-parallel operation—like initializing device memory, performing a small computation, or writing a quick test to ensure your SYCL setup is working.\n",
    "\n",
    "### Waiting for Completion\n",
    "\n",
    "After submitting the task, we call `wait()`. This ensures that our program waits for the GPU to finish running the kernel before continuing. Without `wait()`, the CPU might move on to other tasks before the GPU has finished, which could cause some strange behavior in more complex programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c12ff-72b4-4fa3-8fa2-6c551c73bcaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**<font color=\"red\">SEE example [00-hello.ipynb](examples/00-hello.ipynb)</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5ca8d-07f7-4867-a9d9-aa814e7f86af",
   "metadata": {},
   "source": [
    "# Managing Data\n",
    "\n",
    "Above, we already touched on the differences between the **Buffer/Accessor Mode** and **Unified Shared Memory (USM)**. However, to really drive home their use cases, we'll use this section to dive into when you might choose one or the other. Both have their unique strengths, but the right choice depends on the complexity of your application and the level of control you need over data movement.\n",
    "\n",
    "## Buffers & Accessors\n",
    "\n",
    "The **Buffer/Accessor Model** is one of the most common ways to manage data in SYCL, and it handles a lot of the complexity for you. When you create a **buffer**, SYCL automatically manages data movement between the host (CPU) and device (GPU), ensuring that the correct data is in the right place at the right time.\n",
    "\n",
    "<img width=\"600\" src=\"images/image22.png\">\n",
    "\n",
    "The diagram above shows the relationship between **buffers**, **accessors**, and the device. Notice how buffers are created on the host, but the actual data may be needed on the device. SYCL takes care of the underlying memory transfers, optimizing when and how data is moved.\n",
    "\n",
    "* **Buffers**: Buffers represent a block of data, such as an array or vector, which can be accessed by both the host and device. When a buffer is created, SYCL does not immediately allocate memory on the device. Instead, it waits until the data is needed, which minimizes unnecessary memory transfers.\n",
    "\n",
    "* **Accessors**: Accessors are how kernels (the code running on the device) access the data stored in buffers. By requesting an access mode (e.g., read, write, or read/write), accessors ensure that memory is properly synchronized across devices. This is especially important when working with multiple devices or when ensuring data consistency between the host and device.\n",
    "\n",
    "## Choosing Between Buffer/Accessor Model and USM\n",
    "\n",
    "At this point, you might be wondering when to use **Buffers/Accessors** versus **USM (Unified Shared Memory)**. Both have their advantages, and the decision usually comes down to how much control you want over memory management.\n",
    "\n",
    "**Use the Buffer/Accessor Model when:**\n",
    "\n",
    "* You prefer **automatic memory management**. SYCL handles memory transfers between host and device for you, ensuring that data remains consistent and synchronized. This is ideal if you want SYCL to take care of the details and minimize manual data movement.\n",
    "* You’re working with complex data dependencies. Accessors make it easy to specify when and how data is accessed, especially in multi-kernel or multi-device environments.\n",
    "* You need **robust data synchronization**. SYCL ensures that data is automatically synchronized between host and device when using accessors, simplifying memory consistency across different devices.\n",
    "\n",
    "**Use USM (Unified Shared Memory) when:**\n",
    "\n",
    "* You need **fine-grained control** over memory. USM gives you more flexibility, allowing you to allocate memory directly on the host or device and share that memory between the two. This is great for advanced users who need to control exactly when data is copied or synchronized.\n",
    "* You want to work with **pointers** and direct memory access. USM allows you to allocate shared or device-specific memory and then directly manipulate that memory with pointers, which can be more intuitive for some use cases, especially when porting existing code.\n",
    "\n",
    "Here’s a quick analogy: think of **buffers/accessors** as a fully-managed service—SYCL takes care of everything for you. With **USM**, you’re doing the memory management yourself, but with more control.\n",
    "\n",
    "Depending on your application, both approaches can be useful. For beginners or when working with more straightforward data transfers, **buffers/accessors** are often easier. But if you’re tuning for performance or handling more complex memory management, **USM** might give you the control you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66078be0-75a8-4755-8308-5acb5aa8d4c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Examples Buffer/Accessor Model:**\n",
    "```c++\n",
    "\n",
    "std::vector<int> vectorA(N, 1);  // Vector A filled with 1s\n",
    "\n",
    "// Buffers \n",
    "sycl::buffer<int> bufA {vectorA.data(),vectorA.size() };\n",
    "// or\n",
    "//auto bufA = sycl::buffer{vectorA.data(), sycl::range{N}};\n",
    "\n",
    "// Accessor\n",
    "sycl::accessor accA { bufA, cgh, sycl::read_only};\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98774b-1389-4423-9771-7f6819578614",
   "metadata": {},
   "source": [
    "### Buffers\n",
    "\n",
    "Explain HERE \n",
    "\n",
    "```c++\n",
    "int const size = 10;\n",
    "//  buffer is the memory object to transfer  data between host and device\n",
    "buffer<int> A{ size };\n",
    "// cgh is a handler that defines the command group which contains the task function\n",
    "myQueue.submit([&](sycl::handler &cgh) {\n",
    "    // accessor object allows access the buffer elements\n",
    "    sycl::accessor accA { bufA, cgh};\n",
    "};\n",
    "\n",
    "// host_accessor allows the host to access the buffer memory\n",
    "sycl::host_accessor result(A);  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf4bcb-21cd-45a5-b428-45e75013ecdb",
   "metadata": {},
   "source": [
    "## **Unified Shared Memory (USM) Model:** \n",
    "This model allows for direct data sharing between the host and device, simplifying memory management by eliminating the need for explicit buffers and accessors. Here is the following changes from the buffer/accessor model to USM model:\n",
    "\n",
    "```c++\n",
    "// Allocate memory using USM\n",
    " float* usmA = sycl::malloc_shared<float>(N, gpuQueue);\n",
    "\n",
    " // Initialize USM memory\n",
    " std::copy(vectorA.begin(), vectorA.end(), usmA);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4613df-1477-4623-9313-4f33bc01720a",
   "metadata": {},
   "source": [
    "# How to compile SYCL code\n",
    "\n",
    "Now that we've talked about writing SYCL kernels and managing their memory, let's look at how to actually compile and run them. If you're working with **Intel's DPC++ (Data Parallel C++) compiler**, which is part of Intel's oneAPI toolkit, the typical command for compiling SYCL code looks like this:\n",
    "\n",
    "```bash\n",
    "icpx -fsycl compute.cpp -o ./a.out\n",
    "```\n",
    "\n",
    "Let’s break this down a little so you understand what each part of the command is doing:\n",
    "\n",
    "* `icpx`: This is the **DPC++ compiler** command. It's based on the Intel compiler and is designed to work with SYCL code. If you’ve used **g++** or **clang++** for compiling regular C++ code, this will feel familiar.\n",
    "* `-fsycl`: This flag tells the compiler that you’re working with SYCL. It enables the compilation of SYCL kernels and ensures the compiler can target different devices (like GPUs and CPUs). Without this flag, the compiler would just treat your code as regular C++.\n",
    "* `compute.cpp`: This is the source file we’re compiling. In this case, it contains the SYCL kernel we’ve written.\n",
    "* `-o ./a.out`: This option specifies the output file. After compiling, your program will be saved as `a.out`, which you can then run.\n",
    "\n",
    "### Behind the Scenes\n",
    "\n",
    "When you compile SYCL code, the compiler does more than just translate the C++ into machine code. It’s also figuring out how to split the code between the **host** (your CPU) and the **device** (your GPU or other accelerators). The `-fsycl` flag tells the compiler to handle both sides of the equation—compiling the parts that run on the host, while also generating the necessary device code for the GPU or accelerator.\n",
    "\n",
    "### Running Your Program\n",
    "\n",
    "Once your code is compiled, you can run it just like any other program:\n",
    "\n",
    "```bash\n",
    "./a.out\n",
    "```\n",
    "\n",
    "If everything is set up correctly, this will execute your SYCL code, running your kernels on whatever device you’ve selected—whether that’s a CPU, GPU, or something else. The oneAPI runtime will take care of selecting the right platform and device, or you can specify one directly using the device selectors we talked about earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3ba96-b8b7-4e74-ac13-4c93613bd1d8",
   "metadata": {},
   "source": [
    "### TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9edf07-eac9-4264-bf46-c8da2e2d3728",
   "metadata": {},
   "source": [
    "### Parallel_for\n",
    "\n",
    "Explain HERE \n",
    "\n",
    "```c++\n",
    "myQueue.submit([&](sycl::handler &cgh) {\n",
    "    sycl::accessor accA { bufA, cgh, sycl::write_only};\n",
    "    cgh.parallel_for(N, [=](auto idx) { \n",
    "        accA[i] = idx });\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee66369-fd27-45db-8ff3-7cafe36495cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692fa87-5b2f-4b02-aee3-d7fa09437f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
